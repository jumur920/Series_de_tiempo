[["index.html", "Pronóstico de Ventas de Café en Máquinas Expendedoras Capítulo 1 Introducción 1.1 Justificación de la Elección 1.2 Descripción de la Información a Utilizar 1.3 Fuentes y Permisos de Uso", " Pronóstico de Ventas de Café en Máquinas Expendedoras Luisa Angélica Isaza Sanabria - Juan Andrés Murillo Cadena - Carlos Fabián Villa Infante 2025-05-26 Capítulo 1 Introducción Durante este curso de series de tiempo, hemos decidido trabajar las ventas de café en una máquina expendedora. Detrás de cada café que alguien compra, hay patrones de consumo, hábitos y decisiones que se repiten en el tiempo. Analizar esta información nos permite aplicar modelos de pronóstico reales, útiles y con impacto directo en la toma de decisiones comerciales y operativas. Poder anticipar cuánto café se va a vender en los próximos días, semanas o meses es clave para mejorar la experiencia del cliente, reducir pérdidas y aumentar la eficiencia. 1.1 Justificación de la Elección El café es una de las bebidas más consumidas en todo el mundo, y las máquinas expendedoras son una forma práctica de acceder a él. Nos pareció un caso ideal porque: 1. Ayuda a planificar mejor los inventarios: Prever la demanda permite tener siempre lo justo: ni mucho producto que termine vencido, ni tan poco que dejemos de vender. 2. Hace más eficientes las operaciones: Si sabemos cuándo se vende más café, podemos organizar mejor las recargas y los mantenimientos, ahorrando tiempo y dinero. 3. Permite personalizar promociones:Detectar días u horarios de baja demanda ayuda a lanzar promociones en momentos estratégicos. 4. Mejora la experiencia de quienes compran: Asegurar que los productos favoritos estén disponibles en los momentos clave mejora la satisfacción y fideliza al cliente. 1.2 Descripción de la Información a Utilizar Vamos a utilizar un dataset llamado “Coffee Sales”, publicado por Yaroslav Isaienkov en la plataforma Kaggle. Esta base de datos contiene registros reales de ventas desde marzo de 2024 y sigue actualizándose semanalmente. El dataset incluye: • La fecha y hora de cada transacción • El tipo de café vendido • La cantidad y el método de pago • Información detallada sobre el producto y las preferencias del cliente Todo esto en archivos están en formato .csv que son muy fáciles de trabajar y analizar, ideales para aplicar modelos de series de tiempo. 1.3 Fuentes y Permisos de Uso Una gran ventaja de este dataset es que está disponible bajo una licencia de dominio público (CC0),(Isaienkov (2025)) lo que significa que se puede usar libremente con fines educativos, de análisis y sin restricciones. Además, todos los datos han sido recolectados de forma anónima a partir de informes de la propia máquina expendedora. "],["análisis-grafico-de-series-de-tiempo.html", "Capítulo 2 Análisis grafico de series de tiempo 2.1 Metodología 2.2 Estacionariedad, Diferenciación y Transformaciones 2.3 Conclusiones", " Capítulo 2 Análisis grafico de series de tiempo Este es un análisis temporal de las ventas diarias de una máquina de café, con el objetivo de identificar patrones, tendencias y ciclos estacionales que permitan optimizar la gestión del negocio. Los datos incluyen información sobre la fecha y hora de las ventas, el medio de pago (efectivo o tarjeta), el valor de cada transacción y el tipo de café vendido. El análisis se centra en la variable valor_total (suma de ventas por día) y utiliza tres herramientas principales: el promedio móvil, la función de autocorrelación (ACF) y la descomposición STL. 2.1 Metodología 2.1.1 Datos Los datos abarcan un periodo de 385 días, desde abril 01 de 2024 hasta abril 23 de 2025. La variable analizada, valor_total, representa la suma de las ventas diarias (en dolares). 2.1.2 Promedio móvil Promedio móvil: Se calculó un promedio móvil de 7 días para suavizar las fluctuaciones diarias y destacar tendencias generales en las ventas. La siguiente gráfica muestra las ventas diarias (línea azul) junto con el promedio móvil (línea naranja). Figure 2.1: Ventas diarias con promedio móvil La gráfica muestra una alta variabilidad en las ventas diarias, con picos que alcanzan hasta 800 y caídas cercanas a 0. El promedio móvil revela las siguientes tendencias: Abril-julio 2024: Las ventas promedio crecen de ~300 a ~400, indicando un aumento en la demanda. Julio-octubre 2024: Alcanzan un pico de ~500, mostrando un periodo de alta demanda, posiblemente por festividades o factores estacionales. Octubre 2024-enero 2025: Disminuyen a ~300, reflejando una caída en las ventas durante el invierno. Enero-abril 2025: Se recuperan y estabilizan en ~400, indicando una mejora en la primavera. Esto sugiere una tendencia estacional a largo plazo, con un pico en octubre y una caída en invierno. 2.1.3 Función de Autocorrelación (ACF) La función de autocorrelación (ACF) mide la correlación de las ventas diarias consigo mismas en diferentes rezagos, ayudando a identificar patrones temporales y ciclos estacionales. Figure 2.2: Autocorrelación de ventas La gráfica ACF muestra: Rezagos 1 a 6: Autocorrelaciones significativas (~0.3 a 0.4), indicando una dependencia a corto plazo. Las ventas de un día están correlacionadas con las de los días anteriores, con un efecto que disminuye gradualmente. Rezago 7: Un pico significativo (~0.4), confirmando un ciclo semanal. Esto indica que las ventas tienen un patrón que se repite cada 7 días (por ejemplo, mayor demanda los fines de semana). Rezagos 8 a 14: Autocorrelaciones más pequeñas pero aún significativas, con otro pico en el rezago 14 (segundo ciclo semanal), reforzando el patrón estacional. Este ciclo semanal sugiere que las ventas varían según el día de la semana. 2.1.4 Descomposición STL La descomposición STL separa la serie temporal en tres componentes: tendencia, estacionalidad (ciclo semanal) y residuo. La descomposición STL revela los siguientes patrones: Tendencia: Similar al promedio móvil, muestra un aumento inicial (abril-julio 2024), un pico en octubre (500), una caída en invierno (300), y una recuperación en primavera (~400). Esto confirma una tendencia estacional a largo plazo. Estacionalidad: Oscila entre -20 y 20, con un ciclo que se repite cada 7 días, confirmando el patrón semanal identificado por la ACF. Aunque el efecto estacional es pequeño, indica variaciones según el día de la semana (por ejemplo, mayor demanda los fines de semana). Residuo: Varía entre -300 y 300, mostrando una alta variabilidad. Esto indica que hay fluctuaciones significativas en las ventas que no se explican por la tendencia ni la estacionalidad, posiblemente debido a eventos aleatorios (festivos, promociones, cierres). 2.2 Estacionariedad, Diferenciación y Transformaciones Se analizó la estacionariedad de las ventas y se evaluó la necesidad de diferenciación y transformaciones para controlar tendencia y variabilidad. 2.2.1 Análisis de Estacionariedad La estacionariedad se evaluó con la prueba ADF (Augmented Dickey-Fuller). Una serie se considera estacionaria si su media y varianza son constantes en el tiempo. ## ## Augmented Dickey-Fuller Test ## ## data: ts_ventas ## Dickey-Fuller = -3.5858, Lag order = 7, p-value = 0.0345 ## alternative hypothesis: stationary El valor p de la prueba ADF para la serie original es 0.0345. Dado que el valor p es menor que 0.05, rechazamos la hipótesis nula de no estacionariedad, indicando que la serie es estacionaria. Esto significa que la serie no requiere diferenciación, aunque la descomposición STL y el promedio móvil muestran una tendencia estacional a largo plazo (pico en octubre, caída en invierno, recuperación en primavera). La estacionariedad implica que la media y varianza son relativamente constantes. 2.2.2 Diferenciación Dado que la prueba ADF confirma que la serie ya es estacionaria (valor p = 0.0345 &lt; 0.05), la diferenciación no es necesaria. 2.2.3 Transformaciones La serie original muestra alta variabilidad, con picos grandes (~800) y caídas a 23.02. Esto sugiere una varianza no constante, que podría beneficiarse de una transformación logarítmica para estabilizar la variabilidad. Se verifica si hay valores no positivos:: ## [1] 23.02 El valor mínimo es 23.02, un valor positivo y no cercano a 0. Por lo tanto, se puede aplicar una transformación logarítmica log⁡(y). La gráfica de la serie transformada muestra que los picos se han reducido en escala. Por ejemplo, los picos más altos, que antes alcanzaban 800, ahora están en el rango de log⁡(800)≈6.6, y las caídas a 23.02 ahora son log⁡(23.02)≈3.1. Esto indica que la transformación estabiliza la varianza, haciendo las fluctuaciones más uniformes a lo largo del tiempo. La transformación no elimina la tendencia estacional ni el ciclo semanal ya que la transformación logarítmica afecta principalmente la varianza, no la tendencia ni la estacionalidad. Aunque la serie es estacionaria sin transformación, esta transformación mejora la estabilidad de la serie, lo que puede facilitar el modelado posterior (por ejemplo, SARIMA) y puede mejorar la precisión de las predicciones. 2.2.4 Justificación Diferenciación: No es necesaria, ya que la serie es estacionaria según la prueba ADF (valor p = 0.0345 &lt; 0.05). Transformación logarítmica: Aunque no es estrictamente necesaria para la estacionariedad, la transformación log⁡(y) ayuda a estabilizar la varianza de la serie, que tiene alta variabilidad. 2.3 Conclusiones El análisis temporal de las ventas diarias de la máquina de café revela los siguientes hallazgos: Tendencia estacional a largo plazo: Las ventas crecen hacia octubre (pico de 500), caen en invierno (300), y se recuperan en primavera (~400). Ciclo semanal: Tanto la ACF como la descomposición STL confirman un ciclo de 7 días, indicando que las ventas varían según el día de la semana. Se puede analizar las ventas por día de la semana para identificar días de alta demanda (por ejemplo, fines de semana). Alta variabilidad residual: El residuo de la descomposición STL muestra fluctuaciones significativas (hasta ±300), lo que sugiere que las ventas tienen un componente impredecible. Esto podría deberse a eventos externos (festivos, promociones), que vale la pena investigar para mejorar las predicciones. Estacionariedad y transformaciones: La serie original es estacionaria (prueba ADF, valor p = 0.0345 &lt; 0.05), por lo que la diferenciación no es necesaria. La transformación log estabiliza la varianza, reduciendo la magnitud de las fluctuaciones (de un rango de 23.02 a 800 a ~3.14 a ~6.68 en la escala logarítmica). Aunque la transformación no elimina la tendencia estacional ni el ciclo semanal, mejora la estabilidad de la serie, lo que facilita el modelado posterior. Un modelo como SARIMA puede ser adecuado para capturar la estacionalidad semanal y la tendencia estacional a largo plazo. En resumen, las ventas de la máquina de café presentan patrones claros a nivel semanal y estacional. La serie es estacionaria, por lo que está lista para modelado sin diferenciación. La transformación log⁡(y) mejora la estabilidad de la varianza, haciendo la serie más adecuada para modelos como SARIMA, que pueden capturar el ciclo estacional semanal y la tendencia estacional. "],["métodos-de-holt-winters-y-suavizamiento-exponencial-suavizamiento-exponencial-triple.html", "Capítulo 3 Métodos de Holt-Winters y Suavizamiento Exponencial (Suavizamiento Exponencial Triple) 3.1 Suavizamiento Exponencial Simple 3.2 Holt-Winters Aditivo 3.3 Holt-Winters Multiplicativo 3.4 Comparación de Modelos Holt-Winters", " Capítulo 3 Métodos de Holt-Winters y Suavizamiento Exponencial (Suavizamiento Exponencial Triple) El método Holt-Winters modela promedio, tendencia y estacionalidad. Dado que la serie tiene un ciclo semanal y una tendencia estacional a largo plazo, se probaron los siguientes tipos de suavizamiento: exponencial simple, aditivo y multiplicativo. Se aplican los métodos de Holt-Winters para modelar y predecir las ventas diarias para los próximos 7 días (un ciclo semanal). 3.1 Suavizamiento Exponencial Simple El suavizamiento exponencial simple modela solo el promedio de la serie y no considera tendencia ni estacionalidad, por lo que no es ideal para la serie de tiempo que tiene ambos componentes. Se aplicó a la serie transformada log(y) para evaluar su comportamiento en una escala con varianza estabilizada. Figure 3.1: Suavizamiento Exponencial Simple Como el suavizamiento exponencial simple solo modela la tendencia de la serie (sin tendencia ni estacionalidad), las predicciones son esencialmente un promedio suavizado de los valores históricos. En la escala logarítmica, las predicciones se mantienen constantes en un rango de ~5.8 a ~6 (equivalente a ~300 a ~400 en la escala original), sin reflejar el ciclo semanal ni la tendencia estacional. La gráfica evidencia que este modelo no captura los patrones semanales (como mayores ventas los fines de semana) ni la tendencia estacional a largo plazo. 3.2 Holt-Winters Aditivo En el modelo aditivo, la estacionalidad tiene una amplitud constante, lo que es consistente con la componente estacional de la descomposición STL (oscilando entre -20 y 20). Figure 3.2: Holt-Winters Aditivo El pronóstico con este metodo refleja el ciclo semanal que tiene la serie. La prediccion tiene picos y caidas que coinciden con el compotamiento fluctuante de las ventas reales. Como el modelo es aditivo, la amplitud de las fluctuaciones estacionales es constante, lo que coincide con la descomposición STL (entre -20 y 20). Esto significa que los picos y caídas en las ventas tienen una diferencia fija en valor absoluto. Los intervalos de confianza son relativamente estrechos, lo que indica que el modelo tiene una buena certeza en sus predicciones, aunque la alta variabilidad residual (±300) podría hacer que las ventas reales se desvíen de estas predicciones. 3.3 Holt-Winters Multiplicativo En el modelo multiplicativo, la amplitud de la estacionalidad varía con la tendencia de la serie. Esto puede ser significativo cuando las fluctuaciones sean más grandes en periodos de ventas altas. Figure 3.3: Holt-Winters Multiplicativo Este pronóstico también refleja el ciclo semanal que tiene la serie, pero asume que la amplitud de la estacionalidad varía con la tendencia de la serie. Por ejemplo, si las ventas promedio aumentan, las diferencias entre días de alta y baja demanda (como fines de semana vs. días laborales) se amplifican. Los intervalos de confianza son similares a los del modelo aditivo, pero tiene una amplitud menor en este rango de tiempo posiblemente porque la tendencia es más estable y el enfoque multiplicativo de variabilidad. 3.4 Comparación de Modelos Holt-Winters Se compara la precisión de los modelos aditivo y multiplicativo usando el error cuadrático medio (RMSE) y el error absoluto medio (MAE): ## RMSE MAE ## Additive 140.4213 111.8802 ## Multiplicative 143.8373 115.8820 El modelo Holt-Winters Aditivo es mejor, ya que tiene un RMSE y un MAE más bajos en comparación con el modelo Holt-Winters Multiplicativo. Esto indica que el modelo aditivo tiene un mejor ajuste a los datos y comete errores de predicción más pequeños en promedio. Además, la descomposición STL mostró que la estacionalidad de las ventas tiene una amplitud constante, lo que favorece al modelo aditivo, ya que este asume una estacionalidad constante, mientras que el modelo multiplicativo asume que la estacionalidad varía con el nivel de la serie. Dado que las ventas en ciertos meses presentan variaciones más grandes afectan la tendencia y generar diferencias entre los modelos, por esto el modelo aditivo es más adecuado. En las gráficas de pronóstico, los intervalos de confianza al 95% del método Holt-Winters Multiplicativo presentan una amplitud menor en comparación con los del método Aditivo. Esto indica que el modelo multiplicativo estima una menor incertidumbre en sus predicciones, posiblemente debido a que la tendencia de la serie es relativamente estable en este periodo. En contraste, el modelo aditivo, al asumir una estacionalidad constante, genera intervalos más amplios. RMSE (Root Mean Squared Error): El RMSE mide la raíz del promedio de los errores al cuadrado. Esta medida Penaliza más los errores grandes al elevarlos al cuadrado, lo que lo hace sensible a valores atípicos. MAE (Mean Absolute Error): El MAE mide el promedio de los errores absolutos. Representa el error promedio de las predicciones de manera directa, sin dar mayor peso a errores grandes, lo que lo hace más robusto frente a valores atípicos. La diferencia entre los modelos es de 3.416 en RMSE (2.43%) y 4.0018 en MAE (3.58%). Esta diferencia no se considera significativa, ya que es relativamente pequeña y en valor se diferencia entre 3-4 dólares frente a ventas promedio de 400 y una variabilidad residual de ±300. Dado que la diferencia es insignificante, ambos modelos tienen un rendimiento similar, aunque el aditivo sigue siendo preferible por su mejor ajuste y consistencia teórica con la estacionalidad constante. "],["ajuste-a-un-modelo-lineal-y-estacionario-modelo-arima.html", "Capítulo 4 Ajuste a un modelo lineal y estacionario (Modelo Arima) 4.1 Extensión de variables temporales 4.2 Modelo lineal 4.3 Modelo ARIMA estacional (SARIMA) 4.4 Comparación de Modelos", " Capítulo 4 Ajuste a un modelo lineal y estacionario (Modelo Arima) 4.1 Extensión de variables temporales Se va a enriquecer la fuente de datos con información detallada de la serie de tiempo, agregando el día de la semana (lunes, martes, etc.), el mes del año a cada registro diario. 4.2 Modelo lineal Se crea un modelo de regresión lineal para predecir las ventas diarias (valor_total) utilizando las variables temporales creadas (dia_semana, mes). ## ## Call: ## lm(formula = valor_total ~ dia_semana + mes, data = ventas_diarias) ## ## Residuals: ## Min 1Q Median 3Q Max ## -320.25 -98.99 -3.92 89.29 413.61 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 166.4158 31.1736 5.338 1.65e-07 *** ## dia_semanaMon 52.6861 26.5030 1.988 0.04756 * ## dia_semanaTue 66.7581 26.5110 2.518 0.01222 * ## dia_semanaWed 59.2610 26.5358 2.233 0.02613 * ## dia_semanaThu 24.8365 26.5358 0.936 0.34991 ## dia_semanaFri 77.3926 26.4103 2.930 0.00360 ** ## dia_semanaSat 33.9648 26.4935 1.282 0.20065 ## mesFeb 262.6093 36.3307 7.228 2.86e-12 *** ## mesMar 105.0106 31.5160 3.332 0.00095 *** ## mesApr 9.0262 35.7133 0.253 0.80061 ## mesMay 94.8890 35.9921 2.636 0.00874 ** ## mesJun 54.8875 35.7246 1.536 0.12530 ## mesJul 0.8016 35.4178 0.023 0.98196 ## mesAug 44.7058 35.4074 1.263 0.20753 ## mesSep 115.4321 35.7245 3.231 0.00134 ** ## mesOct 243.3142 35.4072 6.872 2.73e-11 *** ## mesNov 73.2084 35.7026 2.051 0.04102 * ## mesDec 53.5210 35.4393 1.510 0.13185 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 138.2 on 367 degrees of freedom ## Multiple R-squared: 0.2743, Adjusted R-squared: 0.2407 ## F-statistic: 8.159 on 17 and 367 DF, p-value: &lt; 2.2e-16 El modelo tiene coeficientes positivos para todos los días y meses, hay algunos días y meses que son significativos, esto es consistente con el comportamiento que se espera de las ventas, pero el R cuadrado ajustado es de solo 0.2407, Esto indica que el modelo explica ~24% de la variabilidad en las ventas. Esto es un resultado muy bajo pero consistente con la alta variabilidad residual (±300) observada en la descomposición STL, que no puede ser capturada completamente por las variables temporales. 4.3 Modelo ARIMA estacional (SARIMA) Dado que la serie es estacionaria (prueba ADF, valor p = 0.0345 &lt; 0.05), se va ajustar un modelo SARIMA para las ventas con el ciclo semanal. ## Series: ts_ventas ## ARIMA(1,0,1)(0,1,1)[7] ## ## Coefficients: ## ar1 ma1 sma1 ## 0.9456 -0.7941 -0.8238 ## s.e. 0.0271 0.0462 0.0438 ## ## sigma^2 = 19476: log likelihood = -2405.17 ## AIC=4818.34 AICc=4818.44 BIC=4834.08 ## ## Training set error measures: ## ME RMSE MAE MPE MAPE MASE ACF1 ## Training set 4.685073 137.7336 109.1637 -33.30582 59.42362 0.8025019 -0.0478096 4.3.1 Estructura del modelo El modelo ARIMA tiene una estructura (1,0,1)(0,1,1)[7]. Los componentes no estacionales (1,0,1) son: p = 1: Componente autorregresivo (AR) de orden 1. Esto confirma que las ventas actuales dependen linealmente de las ventas del día anterior como se vio en la gráfica ACF. d = 0: No se aplica diferenciación no estacional, lo cual es consistente con el resultado de la prueba ADF (valor p = 0.0345 &lt; 0.05), que indicó que la serie es estacionaria. q = 1: Componente de media móvil (MA) de orden 1. Significa que las ventas actuales dependen de los errores de predicción del día anterior. Los componentes estacionales (0,1,1) son: P = 0: No hay componente autorregresivo estacional. D = 1: Se aplica una diferenciación estacional de orden 1 para eliminar la estacionalidad semanal. Esto significa que el modelo trabaja con las diferencias de las ventas de cada día con el mismo día de la semana anterior (por ejemplo, ventas de un lunes menos las ventas del lunes anterior). Q = 1: Componente de media móvil estacional (SMA) de orden 1. Significa que los errores de predicción a nivel estacional también influyen en las ventas. s = 7: Frecuencia estacional de 7 días, coincide con los ciclos identificados en la gráfica ACF y la descomposición STL. Este modelo SARIMA captura tanto la dependencia a corto plazo (AR(1) y MA(1)) como el ciclo semanal (diferenciación estacional y SMA(1)). Que no haya diferenciación no estacional (d = 0) es consistente, ya que la serie es estacionaria, y la diferenciación estacional (D = 1) elimina el patrón semanal. 4.3.2 Coeficientes del modelo autorregresivo no estacional AR(1): ar1 = 0.9456 (s.e. = 0.0271): El valor de 0.9456 (cercano a 1) indica una fuerte autocorrelación en las ventas, las ventas de un día están altamente correlacionadas con las del día anterior. Esto es consistente con la ACF, que mostró autocorrelaciones significativas en los primeros rezagos (~0.3 a 0.4). El valor del error estándar es 0.0271, al calcular el estadístico t (t = 0.9456 / 0.0271 ≈ 34.89) da 34.89, este valor es mucho mayor a 1.96, por lo que el coeficiente es estadísticamente significativo con un p-valor cercano a 0. media móvil no estacional MA(1) ma1 = -0.7941 (s.e. = 0.0462): El valor negativo indica que los errores de predicción del día anterior tienen un efecto correctivo en las ventas actuales. El error estándar es 0.0462, al calcular el estadístico t da -17.19, su valor absoluto es mucho mayor a 1.96, que lo hace también significativo. media móvil estacional SMA(1) sma1 = -0.8238 (s.e. = 0.0438): El valor de -0.8238 indica que los errores de predicción a estacionales también tienen un efecto correctivo ayudando a modelar el ciclo semanal. El error estándar es 0.0438, su estadístico t es -18.81 por lo que también es significativo. Todos los coeficientes fueron significativos. El término AR(1) captura la dependencia a corto plazo, mientras que el término SMA(1) modela el ciclo semanal. Los términos MA(1) y SMA(1) ayudan a corregir los errores de predicción, mejorando el ajuste del modelo. 4.3.3 Varianza del error y Criterios de información Varianza del error sigma^2 = 19476: Esta es la varianza estimada de los errores del modelo en dolares. La raíz cuadrada de esta varianza es 139.56, este valor es una estimación de la desviación estándar de los errores. log likelihood = -2405.17: Este es el valor mide cómo el modelo se ajusta a los datos. Se usa para calcular los criterios de información (AIC, AICc, BIC). Criterios de información: AIC = 4818.34: Criterio de información de Akaike. Mide el ajuste del modelo penalizando la complejidad. Un valor más bajo indica un mejor modelo. AICc = 4818.44: Versión corregida del AIC para muestras pequeñas. BIC = 4834.08: Criterio de información bayesiano. Mide el ajuste del modelo penalizando más fuertemente la complejidad que el AIC. Estos valores no son directamente interpretables sin comparar con otros modelos SARIMA. 4.3.4 Métricas de error ME (Error Medio) = 4.685073: El error medio indica el sesgo promedio de las predicciones. Un valor de 4.68 sugiere en promedio el modelo tiende a predecir 4.68 unidades más de lo real. Esto es un sesgo pequeño comparando el rango de las ventas que varían entre 23.02 y 800. RMSE (Raíz del Error Cuadrático Medio) = 137.7336: El RMSE mide el error promedio de las ventas en las unidades (dolares) de la serie. Un valor de 137.73 indica que las predicciones del modelo se desvían en promedio en ~137.73 dolares de las ventas reales que es un valor alto pero explicado por la variabilidad residual (±300). MAE (Error Absoluto Medio) = 109.1637: El MAE mide el error promedio en valor absoluto. Un valor de 109.16 indica que, en promedio, las predicciones del modelo se desvían 109.16 unidades de las ventas reales. MPE (Error Porcentual Medio) = -33.30582%: El MPE mide el error porcentual promedio. El valor negativo indica que el modelo tiende a subestimar las ventas en promedio, lo que contradice el ME positivo. Esto puede pasar porque el MPE es sensible a errores relativos con valores pequeños (por ejemplo, días con ventas bajas como 23.02), donde un pequeño error absoluto puede traducirse en un gran error porcentual. MAPE (Error Porcentual Absoluto Medio) = 59.42362%: El MAPE mide el error porcentual absoluto promedio. Un valor de 59.42% indica que, en promedio, las predicciones del modelo se desvían en ~59.42% del valor real. Este valor es alto debido a la alta variabilidad de las ventas (de 23.02 a 800). Igual que con el MPE el MAPE tiende a ser grande cuando hay valores pequeños en la serie porque un error pequeño en términos absolutos resulta en un error porcentual grande. MASE (Error Absoluto Medio Escala) = 0.8025019: El MASE compara el MAE del modelo con el MAE de un modelo ingenuo. Un valor menor a 1 indica que el modelo SARIMA es mejor que el modelo ingenuo. ACF1 (Autocorrelación del primer rezago de los residuales) = -0.0478096: Este valor mide la autocorrelación de los residuales en el primer rezago. Un valor cercano a 0 indica que los residuales del modelo no tienen autocorrelación significativa. Significa que el modelo modela la mayor parte de la estructura temporal de la serie dejando residuales que se comportan como ruido blanco. 4.4 Comparación de Modelos Se comparamos la precisión de los modelos Holt-Winters (Aditivo y Multiplicativo), el modelo lineal, y el modelo SARIMA usando el error cuadrático medio (RMSE) y el error absoluto medio (MAE). ## RMSE MAE ## Additive 140.4213 111.8802 ## Multiplicative 143.8373 115.8820 ## Linear 134.9217 108.0084 ## SARIMA 137.7336 109.1637 El SARIMA tiene el mejor desempeño en términos de RMSE y MAE, lo que sugiere que es el mejor modelo hasta ahora. Esto puede deberse a que el SARIMA modela la estructura autorregresiva y la estacionalidad semanal, mientras que Holt-Winters se basa en suavizamiento y el modelo lineal no captura la estructura temporal. "],["algoritmo-facebooks-prophet.html", "Capítulo 5 Algoritmo Facebook´s Prophet 5.1 Componentes 5.2 Justificación", " Capítulo 5 Algoritmo Facebook´s Prophet 5.1 Componentes Prophet está basado en un modelo aditivo que descompone las series temporal en tres componentes principales: y(t)=g(t)+s(t)+h(t)+ϵt y(t): Variable dependiente a modelar. g(t): Es la tendencia que puede ser lineal o logística. Esta tendencia tiene puntos de cambio automáticos o definidos por el usuario. s(t): Estacionalidad, modelada mediante series de Fourier para capturar patrones periódicos (diarios, semanales, anuales). h(t): Efectos de días festivos o eventos especiales, que pueden ser especificados manualmente. ϵt: Error asumido como ruido blanco. Prophet es muy útil para series temporales con fuerte estacionalidad, datos históricos con patrones estacionales y efectos de eventos externos, como festivos, que impactan las ventas. También es robusto ante valores faltantes, ruido o outliers. 5.1.1 Modelamiento Se crea el modelo usando el algoritmo Prophet sin regresores. ## ds yhat yhat_lower yhat_upper ## 379 2025-03-17 379.3272 202.6345 568.5551 ## 380 2025-03-18 395.2764 196.0289 577.4144 ## 381 2025-03-19 382.8862 204.6521 560.0490 ## 382 2025-03-20 353.0883 155.2315 549.1790 ## 383 2025-03-21 400.6356 212.6812 577.8016 ## 384 2025-03-22 363.9774 169.4093 562.4221 ## 385 2025-03-23 334.8151 147.4709 545.6804 En este caso se modelaron los 7 días siguientes de la venta, los componentes del dataframe resultante son: ds: Fecha. yhat: Valor predicho. yhat_lower: Límite inferior al 80% de confianza. yhat_upper: Límite superior al 80% de confianza. En esta grafica se puede ver que el modelo solo fue capaz de modelar 3 de los 7 puntos cercanos a los valores reales, esto se puede explicar por la alta variabilidad residual (±300) observada en la descomposición STL. Además, puede que los componentes principales (tendencia, estacionalidad y días especiales) estén subestimando sus efectos en el tiempo. 5.1.2 Métricas Se calcula el RMSE y MAE del modelo: ## RMSE Prophet: 196.8354 ## MAE Prophet: 146.5227 Estos resultados son los peores de todos los modelos que se han generado, el resultado es consistente con las conclusiones del analisis de la grafica anterior. 5.1.3 Regresores En Prophet, los regresores son variables externas que se pueden añadir al modelo para mejorar las predicciones. Estas variables se suman al modelo original para capturar efectos que no se explican completamente por la tendencia, la estacionalidad o los festivos. Estas variables se incorporan como términos lineales en la ecuación, quedando: y(t)=g(t)+s(t)+h(t)+β1x1(t)+β2x2(t)+⋯+βnxn(t)+ϵty(t) = g Donde: x1(t),x2(t),…,xn(t): Son los regresores en el tiempo. β1,β2,…,βn: Son los coeficientes que Prophet estima para cada regresor. En tu caso, los regresores que se usarán son dia_semana y mes para capturar mejor los efectos de los días de la semana y los meses del año, buscando un mejor resultado ## RMSE Prophet con regresores: 176.8185 ## MAE Prophet con regresores: 134.5342 La inclusión de regresores mejoró el desempeño de Prophet, reduciendo el RMSE en un 10.2% y el MAE en un 8.2%. Esto confirma que los regresores ayudan a capturar efectos específicos haciendo que el modelo sea más preciso, pero todavía no alcanza el nivel de SARIMA o Holt-Winters. 5.2 Justificación La serie de tiempo que se esta estudiando es numérica y continua, lo cual es típico en problemas de regresión y puede ser tratada como un problema de regresión porque Prophet modela la variable dependiente y(t) = ventas como una función de tiempo, descompuesta en componentes aditivos de tendencia, estacionalidad y días especiales. Los componentes aditivos de Prophet permite interpretar los efectos de cada componente, similar a cómo se interpretan los coeficientes en una regresión. Este enfoque es conceptualmente similar a una regresión no lineal, donde el tiempo actúa como un regresor y los componentes de tendencia y estacionalidad son funciones del tiempo ajustadas al comportamiento de los datos. Además: Sin embargo, Prophet no modela explícitamente la dependencia temporal autorregresiva (como en SARIMA), sino que enfoca el problema como una regresión basada en componentes del tiempo. Esto lo hace más interpretable y fácil de usar, pero puede limitar su capacidad para capturar dinámicas autorregresivas complejas, como se vió en el ACF. Isaienkov, Yaroslav. 2025. “Coffee Sales.” Kaggle. https://www.kaggle.com/datasets/ihelon/coffee-sales. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
